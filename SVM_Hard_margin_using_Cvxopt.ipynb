{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid requirement: '#'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 93, in __init__\n",
      "    req = REQUIREMENT.parseString(requirement_string)\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1654, in parseString\n",
      "    raise exc\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1644, in parseString\n",
      "    loc, tokens = self._parse( instring, 0 )\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1402, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3417, in parseImpl\n",
      "    loc, exprtokens = e._parse( instring, loc, doActions )\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1402, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3739, in parseImpl\n",
      "    return self.expr._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1402, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3400, in parseImpl\n",
      "    loc, resultlist = self.exprs[0]._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1406, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 2711, in parseImpl\n",
      "    raise ParseException(instring, loc, self.errmsg, self)\n",
      "pip._vendor.pyparsing.ParseException: Expected W:(abcd...) (at char 0), (line:1, col:1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_internal\\req\\constructors.py\", line 253, in install_req_from_line\n",
      "    req = Requirement(req)\n",
      "  File \"C:\\Users\\AMAN\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 96, in __init__\n",
      "    requirement_string[e.loc:e.loc + 8], e.msg\n",
      "pip._vendor.packaging.requirements.InvalidRequirement: Parse error at \"'#'\": Expected W:(abcd...)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install cvxopt                                          # INSTALL CVXOPT IN JUPYTER\n",
    "import cvxopt as cpt                                                             # using cvxopt for convex optimization\n",
    "import numpy as np                                                               # for using numpy\n",
    "import pandas as pd                                                              # for using pandas\n",
    "from cvxopt import solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  6.9821e-12  2.0947e-11  2e+02  1e+01  1e+00\n",
      " 1:  1.3894e-13  2.7928e-11  2e+00  1e-01  1e-02\n",
      " 2:  1.3919e-15  2.7928e-11  2e-02  1e-03  1e-04\n",
      " 3: -4.3477e-16  2.7929e-11  2e-04  1e-05  1e-06\n",
      " 4: -4.4867e-14  2.8018e-11  2e-06  1e-07  1e-08\n",
      " 5: -4.4527e-12  3.6828e-11  2e-08  2e-09  1e-10\n",
      "Optimal solution found.\n",
      "20\n",
      "50.0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.7192e-10  1.1158e-09  2e+02  1e+01  1e+00\n",
      " 1:  7.4013e-12  1.4877e-09  2e+00  1e-01  1e-02\n",
      " 2:  7.4136e-14  1.4877e-09  2e-02  1e-03  1e-04\n",
      " 3: -2.3680e-14  1.4877e-09  2e-04  1e-05  1e-06\n",
      " 4: -2.4422e-12  1.4926e-09  2e-06  1e-07  1e-08\n",
      " 5: -2.4817e-10  1.9699e-09  9e-08  8e-09  6e-10\n",
      "Optimal solution found.\n",
      "16\n",
      "60.0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.4952e-11  1.3489e-10  2e+02  1e+01  1e+00\n",
      " 1:  8.9454e-13  1.7980e-10  2e+00  1e-01  1e-02\n",
      " 2:  8.9853e-15  1.7981e-10  2e-02  1e-03  1e-04\n",
      " 3: -3.7294e-16  1.7981e-10  2e-04  1e-05  1e-06\n",
      " 4: -4.6283e-14  1.7990e-10  2e-06  1e-07  1e-08\n",
      " 5: -4.7940e-12  1.8921e-10  3e-08  3e-09  2e-10\n",
      "Optimal solution found.\n",
      "16\n",
      "60.0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.8425e-11 -5.5252e-11  2e+02  1e+01  1e+00\n",
      " 1: -3.6667e-13 -7.3700e-11  2e+00  1e-01  1e-02\n",
      " 2: -3.6907e-15 -7.3701e-11  2e-02  1e-03  1e-04\n",
      " 3: -6.1254e-16 -7.3700e-11  2e-04  1e-05  1e-06\n",
      " 4: -5.7544e-14 -7.3586e-11  2e-06  1e-07  1e-08\n",
      " 5: -5.7324e-12 -6.2270e-11  3e-08  2e-09  2e-10\n",
      "Optimal solution found.\n",
      "23\n",
      "42.50000000000001\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  6.3449e-12  1.9043e-11  2e+02  1e+01  1e+00\n",
      " 1:  1.2626e-13  2.5379e-11  2e+00  1e-01  1e-02\n",
      " 2:  1.2679e-15  2.5379e-11  2e-02  1e-03  1e-04\n",
      " 3: -9.2032e-17  2.5380e-11  2e-04  1e-05  1e-06\n",
      " 4: -1.0471e-14  2.5400e-11  2e-06  1e-07  1e-08\n",
      " 5: -1.0396e-12  2.7460e-11  2e-08  2e-09  1e-10\n",
      "Optimal solution found.\n",
      "23\n",
      "42.50000000000001\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\AMAN\\Desktop\\machine learning\\assignment 2\\creditcard.csv') # read csv file as dataframe\n",
    "df.isnull().values.any()                                                                # check is there any missing vlaue in dataset\n",
    "\n",
    "\n",
    "df_fraud = df[df['Class'] == 1]                                                    # new dataframe of only fraud data                \n",
    "df_non_fraud=df[df['Class']==0]                                                    # new dataframe of only non fraud data\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    df = pd.read_csv(r'C:\\Users\\AMAN\\Desktop\\machine learning\\assignment 2\\creditcard.csv') # read csv file as dataframe\n",
    "    df.isnull().values.any()                                        # check is there any missing vlaue in dataset\n",
    "    df_fraud = df[df['Class'] == 1]                                 # new dataframe of only fraud data                \n",
    "    df_non_fraud=df[df['Class']==0]                                 # new dataframe of only non fraud data\n",
    "    df_f_1=df_fraud.sample(n=100)                                   # take only 100 datas of fraud cases                               \n",
    "    df_n_f_1=df_non_fraud.sample(n=100)                             # take only 100 datas of non fraud cases\n",
    "    df_n_f_1['Class']=-1                                            # converting non fraud class value from 0 to -1 (as we took -1 for other class in SVM)  \n",
    "    final_df=pd.concat([df_f_1,df_n_f_1])                           # final dataframe that contains 100 fraud and non fraud case each\n",
    "    DF=final_df.reindex(np.random.permutation(final_df.index))      # shuffling data\n",
    "    tr_size=int(round(len(DF)*0.8))                                 # for 80 % of train data take size value of 80% data\n",
    "    otpt=DF['Class']                                                # taking our target feature as different column\n",
    "    X=DF.drop(['Class'],axis=1)                                     # take X for input values\n",
    "    x_train=np.asarray(X[:tr_size])                                 # 0 to 80% of inout data as training sample\n",
    "    x_test=np.asarray(X[tr_size:])                                  # remaining 20% data as test sample\n",
    "    y_train=np.asarray(otpt[:tr_size])                              # output training data of 80% size of total\n",
    "    y_test=np.asarray(otpt[tr_size:] )                              # output test data of 20% size\n",
    "    \n",
    "    \n",
    "    q=cpt.matrix(np.ones(tr_size)*-1,tc='d')                        # define q matrix of size 160*1 containig each element=-1                       \n",
    "    G=cpt.matrix(np.identity(tr_size)*-1,tc='d')                    # G is identity matrix with diagonal element = -1 (160*160)\n",
    "    h=cpt.matrix(np.zeros(tr_size))                                 # h is marix of zero  (160*1)\n",
    "    a=cpt.matrix((y_train),tc='d')                                  # a is matrix used to construct A matrix (160*1)\n",
    "    A=cpt.matrix(np.transpose(a),tc='d')                            # A is matrix of size 1*160\n",
    "    b=cpt.matrix(np.zeros(1),tc='d')                                # b is matrix of size 1*1 (element=0)\n",
    "\n",
    "\n",
    "    # To define P some terms are predefined in below statement\n",
    "\n",
    "    y_m=cpt.matrix(y_train,tc='d')                                  # matrix y_i of size 160*1\n",
    "    y_m_T=cpt.matrix(np.transpose(y_m),tc='d')                      # matrix y_j is transpose of y_i of size 1*160\n",
    "    y_m_t=cpt.matrix(np.dot((y_m),(y_m_T)),tc='d')                  # multiplicaiton of y_i*y_j\n",
    "\n",
    "    x_m=cpt.matrix(np.array(x_train),tc='d')                        # matrix x_i of size 160*30\n",
    "    x_m_T=cpt.matrix(np.transpose(x_m),tc='d')                      # matrix x_j is transpose of x_i of size 30*160\n",
    "    x_m_t=cpt.matrix(np.dot((x_m),(x_m_T)),tc='d')                  # multiplicaiton of x_i*x_j\n",
    "\n",
    "    # Now we can define our P\n",
    "\n",
    "    P=cpt.matrix(np.dot((y_m_t),(x_m_t)),tc='d')                    # multiplicaiton of y_i*y_j*x_i*x_j\n",
    "    sol=cpt.solvers.qp(P,q,G,h,A,b,  kktsolver='ldl')               # solve by  optimizing dual equation using cvxopt              \n",
    "    alpha=cpt.matrix(sol['x'])                                      # to obtain matrix containing value of alpha\n",
    "\n",
    "    # for w\n",
    "    t=cpt.matrix(np.transpose(np.multiply(np.array(alpha),np.array(y_m))))  \n",
    "    W=np.dot(t,x_m)                                                 # W is multiplication of alpha,y_m and x_m\n",
    "\n",
    "    x_n_c1=np.transpose(df_f_1.drop(['Class'],axis=1))              # define x of term 1 of equation in line 62\n",
    "    t_1=np.dot(W,x_n_c1)                                            # multiply W and x of term_1 of equatino in line 62 \n",
    "    t_one=np.min(t_1)                                               # min of term 1\n",
    "    x_n_c0=np.transpose(df_n_f_1.drop(['Class'],axis=1))            # define x of term 2 of equation in line 62\n",
    "    t_2=np.dot(W,x_n_c0)                                            # multiply W and x of term_2 of equatino in line 62 \n",
    "    t_two=np.max(t_2)                                               # min of term 2\n",
    "    b=-(1/2)*(t_one+t_two)                                          # b=(-1/2)*(min{y=1}W*x+max{y=-1}W*x)\n",
    "    \n",
    "    a=np.array(np.dot(x_test,np.transpose(W))+b, dtype=float)       # find value of w*x+b=a\n",
    "    c=np.array(y_test, dtype=float)                                 # construct array contain corresponding true value of y\n",
    "    \n",
    "    l=cpt.matrix(a, tc='d')                                         # matrix for a\n",
    "    m=cpt.matrix(c, tc='d')                                         # matrix for c\n",
    "    n=np.multiply(l,m)                                              # element  wise multplication and size=160*1\n",
    "    count=0\n",
    "    for i in range(len(n)):                                         # for loop to count error in our model\n",
    "        if n[i]<1:\n",
    "            count=count+1\n",
    "    print(count)\n",
    "    test_error_1=count\n",
    "    Accuracy=(1-(test_error_1/len(y_test)))*100                     # accuracy =(1-(error/total))*100\n",
    "    print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
